{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_bayes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuOQ-AAG6-xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n9kJtSP9yBf",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpEoE79K9noi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NaiveBayes:\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    n_samples, n_features = X.shape\n",
        "    self._classes = np.unique(y)\n",
        "    n_classes = len(self._classes)\n",
        "\n",
        "    #init mean, var, priors\n",
        "    self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "    self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "    self._priors = np.zeros(n_classes, dtype=np.float64)\n",
        "\n",
        "    for c in self._classes:\n",
        "      X_c = X[c==y]\n",
        "      self._mean[c,:]=X_c.mean(axis=0)\n",
        "      self._var[c,:]=X_c.var(axis=0)\n",
        "      self._priors[c] = X_c.shape[0] / float(n_samples)\n",
        "\n",
        "  def predict(self,X):\n",
        "    y_pred = [self._predict(x) for x in X]\n",
        "    return(y_pred)\n",
        "    \n",
        "  def _predict(self, x):\n",
        "    posteriors = []\n",
        "    for idx, c in enumerate(self._classes):\n",
        "      #print(idx,c)\n",
        "      prior = np.log(self._priors[idx])\n",
        "      class_conditional = np.sum(np.log(self._pdf(idx,x)))\n",
        "      posterior = prior + class_conditional\n",
        "      posteriors.append(posterior)\n",
        "    return(self._classes[np.argmax(posteriors)])\n",
        "\n",
        "\n",
        "    \n",
        "  def _pdf(self, class_idx, x):\n",
        "    mean = self._mean[class_idx]\n",
        "    var = self._var[class_idx]\n",
        "    numerator = np.exp(-(x-mean)**2/(2 * var))\n",
        "    denominator = np.sqrt(2*np.pi*var)\n",
        "    return(numerator/denominator)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl3rdeKSEUZX",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGEM7odmEOnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIylfYRDEl4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  accuracy = np.sum(y_true == y_pred)/len(y_true)\n",
        "  return(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh0uzxTTE0Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,y = datasets.make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=123)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USG41cW1FW49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb = NaiveBayes()\n",
        "nb.fit(X_train, y_train)\n",
        "predictions = nb.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj8Kgy87F57I",
        "colab_type": "code",
        "outputId": "51e9576e-6cfb-4ac3-d9a5-21fe70776480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Naive Bayes classification accuracy \",accuracy(y_test, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes classification accuracy  0.965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFXdvHhOGy5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bootstrap_samples(X,y):\n",
        "  n_samples = X.shape[0]\n",
        "  idxs = np.random.choice(n_samples, size = n_samples, replace=True)\n",
        "  return X[idxs], y[idxs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XcS2kbJeYM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomForest:\n",
        "  def __init__(self,n_)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}